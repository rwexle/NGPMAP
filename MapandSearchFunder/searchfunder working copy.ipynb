{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d1423d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import re\n",
    "import time\n",
    "\n",
    "import pandas as pd\n",
    "import lxml\n",
    "from bs4 import BeautifulSoup\n",
    "from unicodedata import normalize\n",
    "from geopy.geocoders import Nominatim\n",
    "from haversine import haversine\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from openpyxl import load_workbook\n",
    "import xlsxwriter\n",
    "\n",
    "pd.options.display.max_rows = 6000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4413ecfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "URL = 'https://www.searchfunder.com'\n",
    "\n",
    "session = requests.session()\n",
    "\n",
    "front = session.get(URL)\n",
    "csrf_token = re.findall(r'<input type=\"hidden\" name=\"_token\" value=\"(.*)\"', front.text)[0]\n",
    "\n",
    "cookies = session.cookies\n",
    "\n",
    "payload = {\n",
    "    'email': 'mhill@nextgengp.com',\n",
    "    'password': 'ETA1234',\n",
    "    '_token': csrf_token,\n",
    "}\n",
    "\n",
    "r = requests.post(URL + '/auth/login', data=payload, cookies=cookies)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bac05326",
   "metadata": {},
   "outputs": [],
   "source": [
    "searchfunds_HTML = requests.get(URL + '/searchfund/allsearchfunds', cookies=r.cookies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7539708",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "726f8181",
   "metadata": {},
   "outputs": [],
   "source": [
    "datasearchfund_id = re.findall('data-searchfund_id=\"[0-9]+\"',searchfunds_HTML.text)\n",
    "searchfund_data_index = list(map(int,re.findall('[0-9]+',str(datasearchfund_id))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29537ed9",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(searchfund_data_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f01a2013",
   "metadata": {},
   "outputs": [],
   "source": [
    "table = pd.read_html(searchfunds_HTML.text)\n",
    "searchfunds = table[0][table[0]['type'].notna()]\n",
    "searchfunds = searchfunds.reset_index()\n",
    "searchfunds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "475e9fb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "table = pd.read_html(searchfunds_HTML.text)\n",
    "searchfunds = table[0][table[0]['type'].notna()]\n",
    "searchfunds = searchfunds.reset_index()\n",
    "searchfunds.index = searchfund_data_index\n",
    "cols = [0,1]\n",
    "searchfunds.drop(searchfunds.columns[cols], axis=1,inplace=True)\n",
    "#searchfunds.to_csv(\"searchfund_raw2.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a42c6a0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c1b4d97",
   "metadata": {},
   "outputs": [],
   "source": [
    "#enrichment = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5da6723d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#enrichment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "986fe38b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#enrichment.loc[enrichment['searchfund_index'] == 10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a2f5b6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "type(searchfund_data_index[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65ad2eda",
   "metadata": {},
   "outputs": [],
   "source": [
    "enrichment = []\n",
    "for index in searchfund_data_index:\n",
    "    print(index)\n",
    "    data = requests.get(URL + '/searchfund/ajaxsearchfundrow/'+str(index), cookies=r.cookies)\n",
    "    time.sleep(0.05)\n",
    "    soup = BeautifulSoup(data.content, 'html.parser')\n",
    "    \n",
    "    ## Get company info\n",
    "    company_rows=soup.find_all(class_=\"col-md-3\")\n",
    "    try:\n",
    "        searchWebsite = re.split(r'\\t+',company_rows[0].text)[1].strip('\\n')\n",
    "    except:\n",
    "        searchWebsite = \"\"\n",
    "    try:\n",
    "        companyWebsite= re.split(r'\\t+',company_rows[1].text)[1].strip('\\n')\n",
    "    except:\n",
    "        companyWebsite=\"\"\n",
    "    try:\n",
    "        industry = re.split(r'\\t+',company_rows[2].text)[1].strip('\\n')\n",
    "    except:\n",
    "        industry=\"\"\n",
    "    try:\n",
    "        location = re.split(r'\\t+',company_rows[3].text)[1].strip('\\n')\n",
    "    except:\n",
    "        location=\"\"\n",
    "\n",
    "    \n",
    "    \n",
    "    ## Get Searcher info\n",
    "    searchers=[]\n",
    "    try:\n",
    "        searcher_rows=soup.find_all(class_=\"col-md-12\")[0]\n",
    "        for searcher_row in searcher_rows:\n",
    "            try:\n",
    "                searchers.append(re.split(r'\\t+',searcher_row.text)[-1].strip('\\n'))\n",
    "            except:\n",
    "                searchers.append(\"\")\n",
    "        searchers = list(filter(None, searchers))\n",
    "    except:\n",
    "        searchers\n",
    "\n",
    "\n",
    "    ## Get Investor info\n",
    "    investors=[]\n",
    "    try:\n",
    "        investor_rows=soup.find_all(class_=\"col-md-12\")[2]\n",
    "        for investor_row in investor_rows:\n",
    "            try:\n",
    "                investors.append(re.split(r'\\t+',investor_row.text)[-1].strip('\\n'))\n",
    "            except:\n",
    "                investors.append(\"\")\n",
    "        investors = list(filter(None, investors))\n",
    "    except:\n",
    "        investors\n",
    "\n",
    "    ## Get Associate info\n",
    "    associates=[]\n",
    "    try:\n",
    "        associate_rows=soup.find_all(class_=\"col-md-12\")[4]\n",
    "        for associate_row in associate_rows:\n",
    "            try:\n",
    "                associates.append(re.split(r'\\t+',associate_row.text)[-1].strip('\\n'))\n",
    "            except:\n",
    "                associates.append(\"\")\n",
    "        associates = list(filter(None, associates))\n",
    "    except:\n",
    "        associates\n",
    "    \n",
    "    enrichmentData = {'searchfund_index': index, 'searchWebsite': searchWebsite,'companyWebsite': companyWebsite,'industry':industry,'location':location,'searchers':searchers,'investors':investors,'associates':associates}\n",
    "    #print(enrichmentData)\n",
    "    enrichment.append(enrichmentData)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a6d0a8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "enrichmentDF = pd.DataFrame(enrichment)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d258feb",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = requests.get(URL + '/searchfund/ajaxsearchfundrow/6', cookies=r.cookies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5655f163",
   "metadata": {},
   "outputs": [],
   "source": [
    "soup = BeautifulSoup(data.content, 'html.parser')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d6d2bd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Get company info\n",
    "company_rows=soup.find_all(class_=\"col-md-3\")\n",
    "try:\n",
    "    searchWebsite = re.split(r'\\t+',company_rows[0].text)[1].strip('\\n')\n",
    "except:\n",
    "    searchWebsite = \"\"\n",
    "try:\n",
    "    companyWebsite= re.split(r'\\t+',company_rows[1].text)[1].strip('\\n')\n",
    "except:\n",
    "    companyWebsite=\"\"\n",
    "try:\n",
    "    industry = re.split(r'\\t+',company_rows[2].text)[1].strip('\\n')\n",
    "except:\n",
    "    industry=\"\"\n",
    "try:\n",
    "    location = re.split(r'\\t+',company_rows[3].text)[1].strip('\\n')\n",
    "except:\n",
    "    location=\"\"\n",
    "    \n",
    "    \n",
    "## Get Searcher info\n",
    "searchers=[]\n",
    "try:\n",
    "    searcher_rows=soup.find_all(class_=\"col-md-12\")[0]\n",
    "    for searcher_row in searcher_rows:\n",
    "        try:\n",
    "            searchers.append(re.split(r'\\t+',searcher_row.text)[-1].strip('\\n'))\n",
    "        except:\n",
    "            searchers.append(\"\")\n",
    "    searchers = list(filter(None, searchers))\n",
    "    print(searchers)\n",
    "except:\n",
    "    searchers\n",
    "    \n",
    "    \n",
    "## Get Investor info\n",
    "investors=[]\n",
    "try:\n",
    "    investor_rows=soup.find_all(class_=\"col-md-12\")[2]\n",
    "    for investor_row in investor_rows:\n",
    "        try:\n",
    "            investors.append(re.split(r'\\t+',investor_row.text)[-1].strip('\\n'))\n",
    "            index= index +1\n",
    "        except:\n",
    "            investors.append(\"\")\n",
    "    investors = list(filter(None, investors))\n",
    "    print(investors)\n",
    "except:\n",
    "    investors\n",
    "    \n",
    "## Get Associate info\n",
    "associates=[]\n",
    "try:\n",
    "    associate_rows=soup.find_all(class_=\"col-md-12\")[4]\n",
    "    for associate_row in associate_rows:\n",
    "        try:\n",
    "            associates.append(re.split(r'\\t+',associate_row.text)[-1].strip('\\n'))\n",
    "        except:\n",
    "            associates.append(\"\")\n",
    "    associates = list(filter(None, associates))\n",
    "    print(associates)\n",
    "except:\n",
    "    associates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bbfb197",
   "metadata": {},
   "outputs": [],
   "source": [
    "enrichmentDF\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "facdd5ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "#searchfunds = pd.merge([searchfunds, enrichment], how='right',on='searchfund_index')\n",
    "\n",
    "merged = pd.merge(searchfunds, enrichmentDF, left_index=True, right_on='searchfund_index')\n",
    "merged"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08c025d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged['name'] = merged['name'].str.split(\"|\", n = 1, expand = True)[0]\n",
    "merged['formed'] = merged['formed'].str.split(\" \", n = 1, expand = True)[0]\n",
    "merged['acquired'] = merged['acquired'].str.split(\" \", n = 1, expand = True)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96e40af9",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "466c7b25",
   "metadata": {},
   "outputs": [],
   "source": [
    "#pd.to_datetime('formed', errors = 'coerce')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91cdd342",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "276aca0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#convert to datetime\n",
    "merged['formed'] = pd.to_datetime(merged['formed'].astype(str), format = '%Y%m%d', errors = 'coerce')\n",
    "merged['acquired'] = pd.to_datetime(merged['acquired'].astype(str), format = '%Y%m%d', errors = 'coerce')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0cf9970",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42dd648c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# find time it took between starting a search and making an aquisition/ending, non-calculable values are listed as NaN\n",
    "count = 0\n",
    "searchtime = []\n",
    "for val in merged['acquired']:\n",
    "    if (merged['acquired'][count] - merged['formed'][count]).days < 0:\n",
    "        searchtime.append('NaN')\n",
    "    else:\n",
    "        searchtime.append((merged['acquired'][count] - merged['formed'][count]).days)\n",
    "    count += 1\n",
    "merged[\"Search Length\"] = searchtime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76f84461",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fb503bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#convert from list to string\n",
    "##merged['investors'] = merged['investors'].apply(lambda x: x[1:-1])\n",
    "#merged['associates'] = merged['associates'].apply(lambda x: x[1:-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "021e6d18",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e648de0",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged[\"investors\"] = merged[\"investors\"].astype(str).apply(lambda x: x[1:-1])\n",
    "merged[\"searchers\"] = merged[\"searchers\"].astype(str).apply(lambda x: x[1:-1])\n",
    "merged[\"associates\"] = merged[\"associates\"].astype(str).apply(lambda x: x[1:-1])\n",
    "#merged.rename(columns={\"location_x\": \"Search Location\", \"location_y\": \"Acquistion Location\", \"searchfund_index\": \"Searchfund Index\"})\n",
    "#mformat = mformat.replace(u\"\\xa0\", u\" \")\n",
    "#mformat[\"searchers\"][0] = mformat['searchers'][0].replace(u'\\xa0', \" \").encode('utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad73c44c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#removes all ascii characters from searchers column and also removes \\\\xa0 delimiter\n",
    "count = 0\n",
    "for val in merged[\"searchers\"]:\n",
    "    merged[\"searchers\"][count] = merged['searchers'][count].encode(\"ascii\", 'ignore')\n",
    "    asciiremove = merged[\"searchers\"][count].decode()\n",
    "    asciiremove = asciiremove.replace(\"\\\\xa0\", \" \")\n",
    "    merged[\"searchers\"][count] = asciiremove\n",
    "    count += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb1c649f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#removes all ascii characters from investors column and also removes \\\\xa0 delimiter\n",
    "count = 0\n",
    "for val in merged[\"investors\"]:\n",
    "    merged[\"investors\"][count] = merged['investors'][count].encode(\"ascii\", 'ignore')\n",
    "    asciiremove = merged[\"investors\"][count].decode()\n",
    "    asciiremove = asciiremove.replace(\"\\\\xa0\", \" \")\n",
    "    merged[\"investors\"][count] = asciiremove\n",
    "    count += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebf53dbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#removes all ascii characters form the associates column and also removes \\\\xa0 delimiter\n",
    "count = 0\n",
    "for val in merged[\"associates\"]:\n",
    "    merged[\"associates\"][count] = merged['associates'][count].encode(\"ascii\", 'ignore')\n",
    "    asciiremove = merged[\"associates\"][count].decode()\n",
    "    asciiremove = asciiremove.replace(\"\\\\xa0\", \" \")\n",
    "    merged[\"associates\"][count] = asciiremove\n",
    "    count += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f891668",
   "metadata": {},
   "outputs": [],
   "source": [
    "geolocator = Nominatim(user_agent = 'myapplication')\n",
    "count = 0\n",
    "location_lat = []\n",
    "location_lon = []\n",
    "for val in  merged[\"location_x\"]:\n",
    "    location = geolocator.geocode(val,timeout=10)\n",
    "    try:\n",
    "        location_lat.append(location.raw['lat']) \n",
    "        location_lon.append(location.raw['lon'])\n",
    "    except:\n",
    "        location_lat.append('nan') \n",
    "        location_lon.append('nan')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a6c8aea",
   "metadata": {},
   "outputs": [],
   "source": [
    "geolocator = Nominatim(user_agent = 'myapplication')\n",
    "count = 0\n",
    "acq_lat = []\n",
    "acq_lon = []\n",
    "for val in  merged[\"location_y\"]:\n",
    "    location = geolocator.geocode(val,timeout=10)\n",
    "    try:\n",
    "        acq_lat.append(location.raw['lat']) \n",
    "        acq_lon.append(location.raw['lon'])\n",
    "    except:\n",
    "        acq_lat.append('nan') \n",
    "        acq_lon.append('nan')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dee2c30d",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged[\"search long\"] = location_lon\n",
    "merged[\"search lat\"] = location_lat\n",
    "merged[\"acquisition lat\"] = acq_lat\n",
    "merged[\"acquisition long\"] = acq_lon\n",
    "merged = merged.replace('nan', '0')\n",
    "merged['search lat'] =pd.to_numeric(merged['search lat'])\n",
    "merged['search long'] =pd.to_numeric(merged['search long'])\n",
    "merged['acquisition lat'] =pd.to_numeric(merged['acquisition lat'])\n",
    "merged['acquisition long'] =pd.to_numeric(merged['acquisition long'])\n",
    "merged['search lat'] = merged['search lat'].replace(0, \"NaN\")\n",
    "merged['search long'] = merged['search long'].replace(0, \"NaN\")\n",
    "merged['acquisition lat'] = merged['acquisition lat'].replace(0, \"NaN\")\n",
    "merged['acquisition long'] = merged['acquisition long'].replace(0, \"NaN\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb5154bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "distance = []\n",
    "count = 0\n",
    "for val in merged['search lat']:\n",
    "    try:\n",
    "        distance.append(haversine((merged['search lat'][count], merged['search long'][count]), (merged['acquisition lat'][count], merged['acquisition long'][count]), unit = 'mi'))\n",
    "        \n",
    "    except:\n",
    "        distance.append('NaN')\n",
    "    count += 1\n",
    "merged[\"Miles Between Search and Acquisiton\"] = distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "831d4295",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4d3b149",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged = merged.rename(columns={\"location_x\": \"Search Location\", \"location_y\": \"Acquistion Location\", \"searchfund_index\": \"Searchfund Index\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d54551fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged['industry'] = merged['industry'].fillna('', inplace=True)\n",
    "merged.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a04ae56",
   "metadata": {},
   "outputs": [],
   "source": [
    "####### last cell of working on merged data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c82e5908",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged.to_csv(\"searchfund_allV7.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3549dcd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "copy_df = pd.read_csv(\"searchfund_allV6.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efd7a041",
   "metadata": {},
   "outputs": [],
   "source": [
    "copy_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1097509f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#creates a pie chart of the searchfund industry interest, ignoring NaN values\n",
    "industry_count = copy_df.groupby('industry').size()\n",
    "size = str(industry_count.sum())\n",
    "industries = industry_count.index\n",
    "percent = 100 *industry_count/industry_count.sum()\n",
    "patches, texts = plt.pie(industry_count, startangle = 90, radius = 1.2)\n",
    "labels = ['{0} - {1:1.2f} %'.format(i,j) for i,j in zip(industries, percent)]\n",
    "sort_legend = False\n",
    "if sort_legend:\n",
    "    patches, labels, dummy =  zip(*sorted(zip(patches, labels, industry_count),key=lambda x: x[2], reverse=True))\n",
    "plt.legend(patches, labels, loc='upper right', bbox_to_anchor=(-0.1, 1.),\n",
    "           fontsize=8)\n",
    "\n",
    "plt.title('Search Fund Industry Interest By Percentage (Sample Size: ' + size + \")\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "beb66789",
   "metadata": {},
   "outputs": [],
   "source": [
    "#find the success rate/failure rate/ still searching rate of each year listed\n",
    "stages = copy_df['stage'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3f4bdd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "count = 0\n",
    "formed_years = []\n",
    "for val in copy_df['formed']:\n",
    "    try:\n",
    "        formed_years.append(copy_df['formed'][count][:4])\n",
    "    except:\n",
    "        formed_years.append(None)\n",
    "    count += 1\n",
    "copy_df['Year Formed'] = formed_years"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b7fdda1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28e4dd12",
   "metadata": {},
   "outputs": [],
   "source": [
    "#grouping the total searchers by year the founded, and what stage they made it to.... calculating percentage success rate\n",
    "total_searchers = copy_df.groupby([\"Year Formed\"]).size()\n",
    "stage_year = copy_df.groupby(['Year Formed', 'stage']).size()\n",
    "stage_year = stage_year.unstack(level = 1)\n",
    "stage_year.drop(labels = '2040', axis = 0, inplace = True)\n",
    "stage_year[\"Total\"] = total_searchers\n",
    "stage_year[['Acquired','Explore', 'Inactive', 'Raise', 'Search']] = stage_year[['Acquired','Explore', 'Inactive', 'Raise', 'Search']].div(stage_year.Total, axis=0)\n",
    "stage_year = stage_year.fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba129f62",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#outputting the stage_year dataframe to an existing excel file and sheet\n",
    "book = load_workbook(\"output.xlsx\")\n",
    "writer = pd.ExcelWriter(\"output.xlsx\", engine='openpyxl') \n",
    "writer.book = book\n",
    "\n",
    "writer.sheets = dict((ws.title, ws) for ws in book.worksheets)\n",
    "\n",
    "stage_year.to_excel(writer, \"By Vintage\")\n",
    "\n",
    "writer.save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01a6e978",
   "metadata": {},
   "outputs": [],
   "source": [
    "workbook = xlsxwriter.Workbook('output.xlsx')\n",
    "worksheet = workbook.add_worksheet('By Vintage') # Sheet1\n",
    "worksheet = workbook.add_worksheet('WorkLog') # WorkLog"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a06028f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating Bar plot visualizing the breakdown which stage funds are in \n",
    "stage_bar = stage_year[['Acquired', 'Explore', \"Inactive\", 'Raise', 'Search']].plot.bar(stacked = True)\n",
    "plt.title(\"Stage Breakdown of Search Fund By Year\")\n",
    "plt.legend(loc='upper right', bbox_to_anchor=(-0.1, 1.),\n",
    "           fontsize=8)\n",
    "plt.savefig('Stage Barchart.png', bbox_inches = 'tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42eaaa21",
   "metadata": {},
   "outputs": [],
   "source": [
    "##### Below Cells Are For Analyzing Investors on Searchfunder ####"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "763f80bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#creates a list of all investors from searchfunder\n",
    "investor_list = []\n",
    "for val in copy_df['investors']:\n",
    "    try:\n",
    "        investors = val\n",
    "        investors = investors.split(',')\n",
    "        investor_list.extend(investors)\n",
    "    except:\n",
    "        investor_list.append(\"NaN\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d29729c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#returns the list of a row index for an investor, allows you to find which fund they invested by indexing the row of the searchfunder dataframe\n",
    "def get_investor(investor):\n",
    "    investor_index = copy_df['investors'].str.find(investor)\n",
    "    count = 0\n",
    "    indexes = []\n",
    "    for val in investor_index:\n",
    "        if investor_index[count] >= 0:\n",
    "            indexes.append(count)\n",
    "        count += 1\n",
    "    return indexes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4c9ed2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating a dictionary that contains an investors name as the key and the index of all of their investments as the value\n",
    "investors_index = []\n",
    "for investor in investor_list:\n",
    "    investors_index.append(get_investor(investor))\n",
    "investors_dict = {investor_list[i]: investors_index[i] for i in range(len(investor_list))}\n",
    "investors_dict.pop(\"NaN\", None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0f56338",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a75ae59f",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#creates a dictionary with the key as the investor and the companies/industies he invested in as the values\n",
    "investor_businesses = []\n",
    "investor_industries = []\n",
    "business_dict = {key: None for key in investor_list}\n",
    "for key in investors_dict:\n",
    "    business_list = []\n",
    "    industry_list = []\n",
    "    for val in investors_dict[key]:\n",
    "        business_list.append(copy_df['company'][val])\n",
    "        industry_list.append(copy_df['industry'][val])\n",
    "        business_dict[key] = {\"Companies\": business_list, \"Industries\": industry_list}\n",
    "    investor_businesses.append(business_list)\n",
    "    investor_industries.append(industry_list)\n",
    "#print(investor_businesses)\n",
    "#print(investor_industries)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5b701dc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "380af69c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#using the investors index, creating a list that counts which stage an investor has reached in each of their investment\n",
    "investor_success = []\n",
    "for key in investors_dict:\n",
    "    stage_list = []\n",
    "    for val in investors_dict[key]:\n",
    "        stage_list.append(copy_df['stage'][val])\n",
    "        investors_dict[key] = stage_list\n",
    "    investor_success.append(stage_list)\n",
    "    \n",
    "#counting the number of acquisitions an investor has made out of their total investments, then calculating their success rate\n",
    "#appending this new information to the investors dictionary then formatting to a dataframe and exporting to an excel file\n",
    "\n",
    "for key in investors_dict:\n",
    "    acquired = 0\n",
    "    explore = 0\n",
    "    inactive = 0\n",
    "    raising = 0\n",
    "    search = 0\n",
    "    total = len(investors_dict[key])\n",
    "    \n",
    "    #counting the number of each stage that exists\n",
    "    for val in investors_dict[key]:\n",
    "        if val == 'Acquired':\n",
    "            acquired += 1\n",
    "        elif val == 'Explore':\n",
    "            explore += 1\n",
    "        elif val == 'Inactive':\n",
    "            inactive += 1\n",
    "        elif val == 'Raise':\n",
    "            raising += 1\n",
    "        elif val == \"Search\":\n",
    "            search += 1\n",
    "    try:\n",
    "        investors_dict[key] = {\"Acquisitions\": acquired, \"Explore\": explore, \"Inactive\": inactive, 'Raise': raising, \"Search\": search, \"Investments\": total, \"Acquisition Rate\": acquired/total, \"Failure Rate\": inactive/total, \"Still Searching\": (explore + raising + search)/total}\n",
    "    except:\n",
    "        investors_dict[key] = {\"Acquisitions\": acquired, \"Explore\": explore, \"Inactive\": inactive, 'Raise': raising, \"Search\": search, \"Investments\": total, \"Acquisition Rate\": 0, \"Failure Rate\": inactive/total, \"Still Searching\": (explore + raising + search)/total}\n",
    "    \n",
    "\n",
    "#exporting success dataframe to excel        \n",
    "success_df = pd.DataFrame.from_dict(investors_dict)\n",
    "success_df = success_df.T\n",
    "success_df.to_csv(\"Investor Success Rate.CSV\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da5d47c3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2847586",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acf1d592",
   "metadata": {},
   "outputs": [],
   "source": [
    "#get a DF of investors with more than 30 investments\n",
    "lg_investors = success_df[success_df['Acquisitions'].gt(30)].index\n",
    "lg_dict = {key: None for key in lg_investors}\n",
    "\n",
    "for val in lg_investors:\n",
    "    lg_dict[val] = success_df.at[val, \"Acquisition Rate\"]\n",
    "lg_df = pd.DataFrame.from_dict(lg_dict, orient = 'index')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e1e2153",
   "metadata": {},
   "outputs": [],
   "source": [
    "lg_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f1ea09d",
   "metadata": {},
   "outputs": [],
   "source": [
    "success_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9e8b517",
   "metadata": {},
   "outputs": [],
   "source": [
    "copy_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0bffefb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3ec1f1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "states = (\"Alabama (AL) Alaska (AK) Arizona (AZ) Arkansas (AR) California (CA) Colorado (CO) Connecticut (CT) Delaware (DE) District of Columbia (DC) Florida (FL) Georgia (GA) Hawaii (HI) Idaho (ID) Illinois (IL) Indiana (IN) Iowa (IA) Kansas (KS) Kentucky (KY) Louisiana (LA) Maine (ME) Maryland (MD) Massachusetts (MA) Michigan (MI) Minnesota (MN) Mississippi (MS) Missouri (MO) Montana (MT) Nebraska (NE) Nevada (NV) New Hampshire (NH) New Jersey (NJ) New Mexico (NM) New York (NY) North Carolina (NC) North Dakota (ND) Ohio (OH) Oklahoma (OK) Oregon (OR) Pennsylvania (PA) Rhode Island (RI) South Carolina (SC) South Dakota (SD) Tennessee (TN) Texas (TX) Utah (UT) Vermont (VT) Virginia (VA) Washington (WA) West Virginia (WV) Wisconsin (WI) Wyoming (WY)\")\n",
    "states = states.replace(\")\", \"\")\n",
    "states = states.replace(\"(\", \"\")\n",
    "states = states.split(\" \")\n",
    "#geolocator = Nominatim(user_agent = \"myapplicaiton\")\n",
    "search_state = []\n",
    "for val in copy_df['Search Location']:\n",
    "    try:\n",
    "        for state in states:\n",
    "            if any(state in s for s in display_name):\n",
    "                search_state.append(state)\n",
    "                print(search_state)\n",
    "                break\n",
    "            else:\n",
    "                search_state.append(\"Not in US\")\n",
    "    except:\n",
    "        search_state.append(\"NaN\")\n",
    "\n",
    "print(search_state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abfa4a21",
   "metadata": {},
   "outputs": [],
   "source": [
    "for val in copy_df[\"Search Location\"]:\n",
    "    print(val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d42eaaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "states = (\"Alabama (AL) Alaska (AK) Arizona (AZ) Arkansas (AR) California (CA) Colorado (CO) Connecticut (CT) Delaware (DE) District of Columbia (DC) Florida (FL) Georgia (GA) Hawaii (HI) Idaho (ID) Illinois (IL) Indiana (IN) Iowa (IA) Kansas (KS) Kentucky (KY) Louisiana (LA) Maine (ME) Maryland (MD) Massachusetts (MA) Michigan (MI) Minnesota (MN) Mississippi (MS) Missouri (MO) Montana (MT) Nebraska (NE) Nevada (NV) New Hampshire (NH) New Jersey (NJ) New Mexico (NM) New York (NY) North Carolina (NC) North Dakota (ND) Ohio (OH) Oklahoma (OK) Oregon (OR) Pennsylvania (PA) Rhode Island (RI) South Carolina (SC) South Dakota (SD) Tennessee (TN) Texas (TX) Utah (UT) Vermont (VT) Virginia (VA) Washington (WA) West Virginia (WV) Wisconsin (WI) Wyoming (WY)\")\n",
    "states = states.replace(\")\", \"\")\n",
    "states = states.replace(\"(\", \"\")\n",
    "states = states.split(\" \")\n",
    "geolocator = Nominatim(user_agent = \"myapplicaiton\")\n",
    "search_state = []\n",
    "\n",
    "location = copy_df['Search Location'][20]\n",
    "display_name = location.split(\" \")\n",
    "print(location)\n",
    "print(display_name)\n",
    "for state in states:\n",
    "    if any(state in s for s in display_name):\n",
    "        search_state.append(state)\n",
    "        print(search_state)\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2aeaf93",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "states"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2865f9f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb15168a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abb8d9ae",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bba74101",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4672bece",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4753193",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
